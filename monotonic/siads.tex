\documentclass[12pt]{article} \usepackage{amsmath,amsfonts}
%\usepackage{showlabels}
\usepackage[pdftex]{graphicx,color}

\newcommand{\htop}{{h_{\text{top}}}}
\newcommand{\T}{{\cal P}}
\newcommand{\logprob}{{\cal L}}
\newcommand{\measure}{\mu}
\newcommand{\Aop}{{\cal A}}
\newcommand{\Aindicate}{\alpha}
\newcommand{\slope}{s}

\title{Uniform Probability for Subsequences Drawn from a Continuous
  Time Monotonic Process }

\author{Andrew M.\ Fraser}
\begin{document}
\maketitle
\begin{abstract}
  I describe a probability measure for continuous time trajectories that
  are constrained both to lie in within certain bounds and to be
  monotonic.  Roughly, the measure makes all allowed sequences have
  the same probability with respect to a norm.
\end{abstract}

\section*{To Do:}
\label{sec:do}

\begin{itemize}
\item Pictures of allowed pairs
\item Code that calculates for given $\Delta$:
  \begin{itemize}
  \item Stationary distribution
  \item Conditional distribution after $n$ steps or after $\Delta t$
  \end{itemize}
\end{itemize}

I let $\Aop_\tau$ denote the operator for $\tau = \slope \Delta t$ with
continuous $g$.  In turn I define $\Aop_\tau$ in terms of the function
$\Aindicate_\tau$ that has the value one if its arguments are an allowed
pair $\left( g(0), g(\tau) \right)$ and zero otherwise, viz:
\begin{subequations}
  \begin{align}
    \label{eq:indicate}
    \Aindicate(u,v) &\equiv
    \begin{cases}
      1 & 0 \leq u \leq 1,~ 0 \leq v \leq 1,~ v \leq u + \tau\\
      0 & \text{otherwise}
    \end{cases}\\
    \label{eq:operate}
    \left( \Aop_\tau \rho \right)(g) &\equiv \int \Aindicate(h,g)
                                       \rho(h) dh \\
    &= \int_{\max(g-\tau,0)}^1 \rho(h) dh.
  \end{align}
\end{subequations}
I use the following notation for an eigenvalue and eigenfunction of
$\Aop_\tau$:
\begin{equation*}
 \left( \Aop_\tau \rho_\lambda \right)(g) = \lambda \rho_\lambda (g)
\end{equation*}
Look at the picture and see
\begin{align*}
  \rho_\lambda(g) &= a \text{ constant } \forall g \leq \tau\\
  \lambda a_\lambda &= \int_0^1 \rho_\lambda(h) dh \\
  \lambda \rho_\lambda(g) &= \int_{g-\tau}^1 \rho_\lambda(h) dh ~~\forall
  g > \tau\\
  \lambda \frac{\partial}{\partial g} \rho_\lambda(g) &=
                      - \rho_\lambda(g-\tau)~~\forall g > \tau
\end{align*}


\section{Introduction}
\label{sec:introduction}
\begin{description}
\item[Motivation:] Priors for regions in function space constrained by
  physical laws.  Cite Hixson2000, Fritz1996,
  Pemberton2011LA-UR-11-04999, and FraserLA-UR-13-21824
\item[Connection to Information Theory:] Theorem 8 of Shannon.  Define
  stationary and Markov for discrete time discrete value process.
\item[Connection to Statistical Mechanics:] Jaynes maximum entropy
  derivation of Maxwell Boltzmann distribution.  Coordinate dependent.
\item[Connection to path integrals:]
\item[Not Levy process:] Connection to Brownian motion
\item[Outline:]
\end{description}

\section{Specific Problem}
\label{sec:specific}

I seek a \emph{uniform} distribution on a \emph{restricted} set of
functions.  Figure~\ref{fig:bounds} illustrate the set which I define
by the following constraints\footnote{This an undecidable set.}:
\begin{subequations}
  \label{eq:f_def}
  \begin{description}
  \item[Bounded:] For all values of the independent variable $t$ the
    function lies between $1-t$ and $-t$,
    \begin{equation}
      \label{eq:bounded_f}
      -t \leq f(t) \leq 1-t
    \end{equation}
  \item[Monotonic:] The function is monotonic,
    \begin{equation}
      \label{eq:monotonic_f}
      f(t+\delta) \leq f(t) ~ \forall (t,\delta): \delta \geq 0
    \end{equation}
  \end{description}
\end{subequations}

\begin{figure*}
  \centering
  \resizebox{0.75\textwidth}{!}{\includegraphics{bounds.pdf}}
  \caption{Bounds on allowed functions}
  \label{fig:bounds}
\end{figure*}
If one derives a new function $g$ by shifting $f$ by $t$, ie,
\begin{equation}
  \label{eq:shift}
  g(t) = f(t) + t,
\end{equation}
then the constraints \eqref{eq:f_def} on $f$ imply the following
constraints on $g$:
\begin{subequations}
  \label{eq:g_def}
  \begin{align}
    \label{eq:bounded_g}
    0 &\leq g(t) \leq 1 ~ \forall t\\
    \label{eq:monotonic_g}
    g(t+\delta) &\leq g(t)+\delta ~ \forall(t,\delta): \delta \geq 0  
  \end{align}
\end{subequations}

While Eqns.~\eqref{eq:g_def} describe the constraints that pretty
simply, the goal of this paper is the more difficult task of defining
a uniform distribution over the set.  I require that the probability
measure $\measure$ have the following properties:
\begin{description}
\item[Stationary:] 
\item[Consistent:] 
\end{description}


\section{A simple example}
\label{sec:example}

Consider the adjacency matrix
\begin{equation}
  \label{eq:A}
  A = \begin{bmatrix} 1 & 1 \\ 1 & 0 \end{bmatrix},
\end{equation}
the schematic of the corresponding finite state Markov process in
Figure~\ref{fig:mt2}, and its probability matrix
\begin{equation}
  \label{eq:T}
  \T = \begin{bmatrix} a & b \\ c & 0 \end{bmatrix}.
\end{equation}

\begin{figure*}
  \centering
  \resizebox{0.4\textwidth}{!}{\input{mt2.pdf_t} }
  \caption{A schematic of the finite state Markov process specified by
  Equation~\eqref{eq:T}.}
  \label{fig:mt2}
\end{figure*}

Given values for $a$, $b$, and $c$, one can solve
\begin{equation}
  \label{eq:stationary}
  \mu = \mu \T
\end{equation}
for the stationary distribution $\mu$ and from there find the entropy
rate $h$ by
\begin{equation}
  \label{eq:rate}
  h = \sum_i \mu_i H(J|i)
\end{equation}
where
\begin{equation*}
  H(J|i) \equiv -\sum_j \T_{i,j} \log (\T_{i,j})
\end{equation*}
is the familiar $P\log(P)$ formula.

\subsection{Parameters of $\T$ that maximize $h$}
\label{sec:max}

For the maximum entropy values, given a trajectory length $N$, all
trajectories must have almost the same probability.  Since all
trajectories are composed of loops in a cycle basis, the following
equation must hold
\begin{equation}
  \label{eq:excycle}
  a^2 = b\cdot c.
\end{equation}
That combined with the normalization constraints for the two nodes
\begin{align*}
  a + b &= 1 \\
  c &= 1
\end{align*}
is sufficient to specify the solution
\begin{align*}
  a &= \frac{2}{1+\sqrt{5}} \approx          0.61803\\
  b &= \frac{\sqrt{5}-1}{1+\sqrt{5}} \approx 0.38197\\
  c &= 1.
\end{align*}
Solving \eqref{eq:stationary} for that specification of $\T$ yields
\begin{align*}
  \mu &=  \begin{bmatrix} \frac{1+\sqrt{5}}{2\sqrt{5}}, &
    \frac{\sqrt{5}-1}{2\sqrt{5}} \end{bmatrix} \\
  h &= \log\left(\frac{1+\sqrt{5}}{2}\right).
\end{align*}


\subsection{Topological entropy $\htop$}
\label{sec:htop}

The topological entropy of a directed graph specified by an adjacency
matrix $A$ is the rate at which the number of trajectories grows with
length.  If $n(t)\equiv\begin{bmatrix} n_1(t),&n_2(t)\end{bmatrix}$
denotes the number of trajectories of length $t$ that end in the two
states of Figure \ref{fig:mt2}, then
\begin{align*}
  n(1) &= \begin{bmatrix} 1,&1\end{bmatrix} \text{ and} \\
  n(t+1) &= n(t) A.
\end{align*}
Thus
\begin{align*}
  n(t) &= \begin{bmatrix} 1,&1\end{bmatrix} A^t \\
  \text{and }\lim_{t\rightarrow \infty} \frac{1}{t} \log n_1(t) &=
  \lambda
\end{align*}
where $\lambda$ is the largest eigenvalue of $A$.

Solving the eigenvalue problem yields
\begin{equation*}
  \htop = \log\left(\frac{1+\sqrt{5}}{2}\right).
\end{equation*}

The topological entropy provides one more equation of constraint on
the equations that the values in $\T$ must satisfy for maximizing $h$.
Rather than the single equation \eqref{eq:excycle}, the pair
\begin{equation*}
  - \htop = 2\log(a) = \log(b) + \log(c)
\end{equation*}
must hold.

\section{A Power Iteration Approach}
\label{sec:algorithm}

I will use the solution to this problem to characterize the
distribution of long trajectories in a system defined by an adjacency
matrix $A$.  I want the distribution to be uniform over all allowed
trajectories.

Given a list of allowed trajectories of length $2T$, I could
approximate the value of $\T_{i,j}$ by
\begin{equation*}
  \hat \T_{i,j} = \frac{_{2T}n_{T,T+1}(i,j)}{_{2T}n_{T}(i)},
\end{equation*}
where $_{2T}n_{T}(i)$ denotes the number of trajectories of length
$2T$ for which $i$ is the value at position $T$ and similarly
$_{2T}n_{T,T+1}(i,j)$ denotes the number of trajectories that have
values $i$ and $j$ at positions $T$ and $T+1$ respectively.  While the
exponential growth of the number of trajectories suggests that
implementing the estimate for large $T$ is not feasible, power
iterations for left and right eigenvectors of $A$ make it easy.

The number of allowed sequences of length say six that exactly matches
a given sequence is either zero or one and can be written as
\begin{equation*}
  _6n_{1,2,3,4,5,6}(a,b,c,d,e,f) = A_{a,b}A_{b,c}A_{c,d}A_{d,e}A_{e,f}.
\end{equation*}
The number of sequences that are only required to match at positions
three and four is
\begin{equation*}
 _6n_{3,4}(c,d) =  \sum_{a,b,e,f} {_6n}_{1,2,3,4,5,6}(a,b,c,d,e,f) =
 \sum_{a,f} \left(A^2\right)_{a,c} A_{c,d} \left(A^2\right)_{d,f}.
\end{equation*}
Similarly
\begin{equation*}
 _{202}n_{101,102}(c,d) = \sum_{a,f} \left(A^{100}\right)_{a,c} A_{c,d} \left(A^{100}\right)_{d,f}.
\end{equation*}

I define (and calculate) $R(t)$ and $L(t)$ recursively with the
following power iteration scheme
\begin{align*}
  L(1) &= \begin{bmatrix} 1,&1,&\cdots,&1,&1\end{bmatrix} \\
  N_L(t) &= \left| L(t) \right| \\
  L(t+1) &= \frac{L(t) A}{N_L(t)} \\
  R(1) &= L^{\text{T}}(1) \\
  N_R(t) &= \left| R(t) \right| \\
  R(t+1) &= \frac{A R(t)}{N_R(t)}.
\end{align*}
Note that as $t$ increases, $R(t)$ and $L(t)$ converge quickly to the
right and left eigenvectors respectively of $A$ that correspond to the
largest eigenvalue and I can calculate
\begin{equation}
  \label{eq:N}
   _{2(T+1)}n_{T+1,T+2}(c,d) \propto \left(L(T)\right)_c  A_{c,d}
   \left(R(T)\right)_d
\end{equation}
pretty easily.  With results from \eqref{eq:N} for a large enough $T$
to ensure convergence, one can calculate estimates $\hat \mu$ and
$\hat \T$ of the stationary distribution and transition probabilities
respectively as follows.
\begin{align*}
  \tilde L &= L(T) \\
  \tilde R &= R(T) \\
  \tilde P_{i,j} &= \tilde L_i A_{i,j} \tilde R_j \\
  \tilde m_i &= \sum_j \tilde P_{i,j} \\
  \hat \mu &= \frac{\tilde m}{\sum_i \tilde m_i} \\
  \hat \T_{i,j} &= \frac{\tilde P_{i,j}}{\tilde m_i}
\end{align*}
Maxentropic Markov chains appears in:\\
IEEE Transactions on Information Theory, \\
Date of Publication: Jul 1984\\
Author(s): Justesen, J.\\
Hoholdt, T.\\
Volume: 30 , Issue: 4\\
Page(s): 665 - 667

\section{Composition}
\label{sec:composition}

\begin{align*}
  \left( P(0\mapsto 1) \right)_{i,j} &= \frac{L_i A_{i,j} R_j}
    {\lambda z \frac{\sum_k L_i A_{i,k} R_k}{\lambda z}} \\
  &= \frac{A_{i,j} R_j}{\lambda R_i} \\
  \left( P(0\mapsto 2) \right)_{i,j} &=
     \sum_k \frac{A_{i,k} R_k}{\lambda R_i}
            \frac{A_{k,j} R_j}{\lambda R_k} \\
  &= \frac{(A^2)_{i,j} R_j}{\lambda^2 R_i}                                       
\end{align*}
If $B$ is the adjacency matrix for twice the step size of $A$,
sufficient conditions for consistency are
\begin{align*}
  B R &= \gamma R \\
  \frac{B_{i,j} R_j}{\gamma R_i} &= \frac{(A^2)_{i,j} R_j}{\lambda^2
                                   R_i} \text{or}\\
  (A^2)_{i,j} &= \frac{\lambda^2}{\gamma} B_{i,j}.
\end{align*}
The conditions are not plausible because if it is possible to get from
$i$ to $j$ in two steps, ie, $B_{i,j}=1$, the number of ways to get
from $i$ to $j$ in two steps will vary depending on the values of $i$
and $j$.

\section{Repetition}
\label{sec:repetition}

Here I've typed up hand written alternative notation.  For the one
step joint probability
\begin{align*}
  P_{j,k} &= \lim_{n\rightarrow \infty} \frac {\sum_{i,l} \left(A^n
            \right)_{i,j} A_{j,k}  \left(A^n \right)_{i,j} }{N_n}
            \text{ where the normalization } N_n \text{ makes} \\
  \sum_{j,k}P_{j,k} &= 1   \\
  P_{j,k} &= L_j A{j,k} R_k \text{ where } L,R \text{ are the left and right
    eigenvectors of } A \\
  P_{k|j} &= \frac{L_j A{j,k} R_k}{\sum_k L_j A{j,k} R_k} \\
  &= \frac{L_j A{j,k} R_k}{\lambda L_j R_j} \\
  &= \frac{A_{j,k} R_k}{\lambda R_j}
\end{align*}
For $n$ steps rather than one, the same calculations yield
\begin{align*}
  P_{k|j}(x(n)|x(0)) &= \frac{\left( A \right)^n_{j,k} R_k}{\lambda^n
                       R_j} \\
  &\propto \left( \delta_j \cdot A^n \right)_k R_k
\end{align*}


\end{document}

%%%---------------
%%% Local Variables:
%%% eval: (TeX-PDF-mode)
%%% End:
